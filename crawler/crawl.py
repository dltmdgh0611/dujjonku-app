"""
ë‘ì«€ì¿ ë§µ í¬ë¡¤ëŸ¬
10ë¶„ë§ˆë‹¤ GitHub Actionsì—ì„œ ìë™ ì‹¤í–‰
"""

import requests
import json
from datetime import datetime, timezone, timedelta

URL = "https://www.dubaicookiemap.com"
OUTPUT = "public/stores.json"
KST = timezone(timedelta(hours=9))

def crawl():
    print("ğŸª í¬ë¡¤ë§ ì‹œì‘...")
    
    try:
        res = requests.get(URL, timeout=30, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        html = res.text
        print(f"âœ… HTML ë¡œë“œ ({len(html):,} bytes)")
    except Exception as e:
        print(f"âŒ ì‹¤íŒ¨: {e}")
        return None
    
    # Next.js self.__next_f.push ì•ˆì— cafes ë°ì´í„° ì°¾ê¸°
    print("ğŸ” self.__next_f.push ì•ˆì—ì„œ cafes ì°¾ê¸°...")
    # ì´ìŠ¤ì¼€ì´í”„ëœ í˜•íƒœë¡œ ì°¾ê¸°
    marker = '\\"cafes\\":['
    start = html.find(marker)
    
    if start == -1:
        # ì´ìŠ¤ì¼€ì´í”„ ì—†ëŠ” í˜•íƒœë¡œë„ ì‹œë„
        marker = '"cafes":['
        start = html.find(marker)
    
    if start == -1:
        print("âŒ cafes ì—†ìŒ")
        print(f"ğŸ“„ HTML ìƒ˜í”Œ (ì²˜ìŒ 200ì): {html[:200]}")
        return None
    
    print(f"âœ… cafes ë°œê²¬! ìœ„ì¹˜: {start}, íŒ¨í„´: {marker}")
    
    # cafes ë°°ì—´ ì‹œì‘ ìœ„ì¹˜
    arr_start = start + len(marker) - 1
    depth = 0
    arr_end = arr_start
    
    # ë°°ì—´ ë ì°¾ê¸° (ì´ìŠ¤ì¼€ì´í”„ ê³ ë ¤)
    i = arr_start
    while i < len(html):
        c = html[i]
        # ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬: \" ëŠ” ë¬´ì‹œ
        if i > 0 and html[i-1] == '\\':
            i += 1
            continue
        
        if c == '[':
            depth += 1
        elif c == ']':
            depth -= 1
            if depth == 0:
                arr_end = i + 1
                break
        i += 1
    
    # JSON ë¬¸ìì—´ ì¶”ì¶œ ë° ì´ìŠ¤ì¼€ì´í”„ ì œê±°
    json_str = html[arr_start:arr_end]
    # ì´ìŠ¤ì¼€ì´í”„ëœ ë”°ì˜´í‘œ ì œê±°
    json_str = json_str.replace('\\"', '"')
    
    try:
        cafes = json.loads(json_str)
        print(f"âœ… {len(cafes)}ê°œ ì¹´í˜ ì¶”ì¶œ")
        return process_cafes(cafes)
    except Exception as e:
        print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"ğŸ“„ JSON ìƒ˜í”Œ (ì²˜ìŒ 200ì): {json_str[:200]}")
        return None

def process_cafes(cafes):
    """ì¹´í˜ ë°ì´í„° ê°€ê³µ ë° ì €ì¥"""
    # ì •ë¦¬ (í•„ìš”í•œ í•„ë“œë§Œ, ìš©ëŸ‰ ìµœì†Œí™”)
    data = []
    for c in cafes:
        data.append({
            "n": c.get("name", ""),
            "a": c.get("address", ""),
            "y": c.get("lat", 0),
            "x": c.get("lng", 0),
            "s": c.get("stock_count", 0),
            "u": c.get("naver_place_url", "")
        })
    
    # ì¬ê³  ìˆëŠ” ê³³ ë¨¼ì €
    data.sort(key=lambda x: (x['s'] == 0, -x['s']))
    
    available = sum(1 for d in data if d['s'] > 0)
    
    output = {
        "t": datetime.now(KST).strftime("%m/%d %H:%M"),
        "c": len(data),
        "a": available,
        "d": data
    }
    
    with open(OUTPUT, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, separators=(',', ':'))
    
    print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {len(data)}ê°œ (ì¬ê³ ìˆìŒ: {available})")
    return output

if __name__ == "__main__":
    crawl()
